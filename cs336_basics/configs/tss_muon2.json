{
    "seed": 32,
    "data": {
        "train": "./data/TinyStoriesV2-GPT4-train.npy",
        "valid": "./data/TinyStoriesV2-GPT4-valid.npy",
        "dtype": "uint16"
    },
    "model": {
        "vocab_size": 10048,
        "context_length": 512,
        "d_model": 768,
        "num_layers": 12,
        "num_heads": 16,
        "d_ff": 2048,
        "rope_theta": 1e4,
        "device": "cuda"
    },
    "optimizer": {
        "type": "muon",
        "muon_lr": 4e-2,
        "muon_momentum": 0.95,
        "lr": 1e-3,
        "betas": [0.9, 0.95],
        "eps": 1e-8,
        "weight_decay": 0.1
    },
    "train": {
        "batch_size": 64,
        "steps": 5000,
        "lr_scheduler": "wsd",
        "lr_max": 1e-3,
        "lr_min": 1e-6,
        "t_w": 300,
        "t_c": 4500,
        "grad_clip": 1.0,
        "accum_steps": 4,
        "save": {
            "enable": true,
            "interval": 100,
            "to": "./dist/ckpt.pt"
        }
    },
    "tokenizer": {
        "vocab_path": "./data/TinyStoriesV2-GPT4-train_vocab.pkl",
        "merges_path": "./data/TinyStoriesV2-GPT4-train_merges.pkl",
        "special_tokens": ["<|endoftext|>"]
    },
    "infer": {
        "kv_cache": false,
        "checkpoint": "./dist/saves/checkpoint_2399_1.64.pt"
    }
}